generator.id = 0

metrics.csv {
  enabled = false
  period = 5s
  directory = ./metrics
}

popeye.pipeline {
  channel {
   type = kafka
   kafka = ${common.popeye.pipeline.kafka} {
     topic = popeye-points
     zk.quorum = "localhost:2181"
     broker.list = "localhost:9092"
   }
  }

  channelReaders = {
    opentsdb-reader = {
      mainSink = ${common.popeye.pipeline.hbase-sink} {
        type = fail
        read-chunk-size = 10
        zk.quorum = "localhost:2182"
        topic = "popeye-points"
      }
      dropSink = {
        type = bulkload-sink
        kafka = ${common.popeye.pipeline.kafka} {
          topic = popeye-points-drop
          group = opentsdb
          max-lag = 300s
          zk.quorum = "localhost:2181"
          broker.list = "localhost:9092,localhost:9091"
        }
        storage = hbaseStorage
        jobRunner = {
          restart.period = 15s
          zk = {
            quorum = "localhost:2181/popeye"
            session.timeout = 5s
            connection.timeout = 5s
          }
          output.path = /tmp/hadoop/output
          jars.path = /popeye/lib
          hadoop.conf.paths = ["/home/quasi/programming/sandbox/hadoop/hadoop-2.3.0-cdh5.0.0/etc/hadoop/mapred-site.xml",
                               "/home/quasi/programming/sandbox/hadoop/hadoop-2.3.0-cdh5.0.0/etc/hadoop/core-site.xml"]
        }
        hbase = {
          zk.quorum.hosts = "localhost"
          zk.quorum.port = 2182
        }
      }
    }
  }

  sources = {
    opentsdb-source = ${common.popeye.pipeline.telnet} {
      port = 4444
    }
  }
}

popeye.query = {
  db = {
    zk.quorum = "localhost:2182"
  }

  server = {
    type = opentsdb
    http.listen = "localhost:8080"
  }
}



akka {

#  loglevel = "DEBUG"

  actor {
    debug {
#         event-stream = on
#         autoreceive = on
#         lifecycle = on
#         fsm = on
#         unhandled = on
#         receive = on
#         router-misconfiguration = on
    }
  }
}

