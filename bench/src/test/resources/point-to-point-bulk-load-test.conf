generator.id = 0

metrics.csv {
  enabled = false
  period = 5s
  directory = ./metrics
}

popeye.pipeline {
  channel {
    type = kafka
    kafka = ${common.popeye.pipeline.kafka} {
      topic = popeye-points
      zk.quorum = ${popeye.kafka.zk.quorum}
      broker.list = "localhost:9092"
    }
  }

  channelReaders = {
    opentsdb-reader = {
      mainSink.type = "fail"
      dropSink = {
        type = "bulkload-sink"
        storage = hbaseStorage
        kafka = ${common.popeye.pipeline.kafka} {
          topic = popeye-points-drop
          zk.quorum = ${popeye.kafka.zk.quorum}
          broker.list = "localhost:9092"
          producer = {
            high-watermark = 20000
            low-watermark = 1000
          }
        }
        hbase = {
          zk.quorum = ${popeye.hbase.zk.quorum}
        }
        zk = {
          quorum = ${popeye.popeye.zk.quorum}
          session.timeout = 5s
          connection.timeout = 5s
        }
        job = {
          hadoop.conf.paths = []
          output.hdfs.path = ${popeye.job.output.path}
          jars.hdfs.path = ${popeye.job.jars.path}
          restart.period = ${popeye.job.restart.period}
        }
      }
    }
  }

  sources = {
    opentsdb-source = ${common.popeye.pipeline.telnet} {
      port = 4444
    }
  }
}

popeye.prepare-storage = {
  timeout = 300s
  lock = {
    zk.quorum = "localhost:2181"
    path = /popeye/lock
  }
  db = {
    zk.quorum = "localhost:2182"
    splits = 100
    storage = hbaseStorage
  }
}

popeye.query = {
  db = {
    zk.quorum = ${popeye.hbase.zk.quorum}
  }

  server = {
    type = opentsdb
    http.listen = "localhost:8080"
  }
}


akka {

  #  loglevel = "DEBUG"

  actor {
    debug {
      #         event-stream = on
      #         autoreceive = on
      #         lifecycle = on
      #         fsm = on
      #         unhandled = on
      #         receive = on
      #         router-misconfiguration = on
    }
  }
}

